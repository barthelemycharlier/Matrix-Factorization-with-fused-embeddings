{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab045f04",
   "metadata": {},
   "source": [
    "Simple UserReg Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2c7e8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (610, 4980), Test shape: (610, 4980)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 5/5 [00:02<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 7/7 [00:03<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg:  33%|███▎      | 3/9 [00:01<00:03,  1.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     14\u001b[39m model = UserReg(k=\u001b[32m8\u001b[39m, lr=\u001b[32m0.01\u001b[39m, lambda_reg=\u001b[32m0.02\u001b[39m, beta_reg=\u001b[32m8.0\u001b[39m, bias_init=\u001b[33m\"\u001b[39m\u001b[33mmedium_adapted_mean\u001b[39m\u001b[33m\"\u001b[39m, num_iterations=\u001b[38;5;28miter\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Fit on training data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Predict full matrix\u001b[39;00m\n\u001b[32m     21\u001b[39m preds = model.predict()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/DataScience Lab1/assignment1-2025-circuit-virtuel/userreg.py:102\u001b[39m, in \u001b[36mUserReg.fit\u001b[39m\u001b[34m(self, R)\u001b[39m\n\u001b[32m     99\u001b[39m mean_Q = np.mean(\u001b[38;5;28mself\u001b[39m.Q[Iu, :], axis=\u001b[32m0\u001b[39m)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m Iu:\n\u001b[32m    101\u001b[39m     e_ui = R_filled[u, i] - (\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m         \u001b[38;5;28mself\u001b[39m.bu[u] + \u001b[38;5;28mself\u001b[39m.bi[i] + \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mP\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m     )\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# Update biases\u001b[39;00m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mself\u001b[39m.bu[u] += \u001b[38;5;28mself\u001b[39m.lr * (e_ui - \u001b[38;5;28mself\u001b[39m.lambda_reg * \u001b[38;5;28mself\u001b[39m.bu[u])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/DataScience Lab1/assignment1-2025-circuit-virtuel/datascience_lab_1/lib/python3.12/site-packages/numpy/_core/multiarray.py:769\u001b[39m, in \u001b[36mdot\u001b[39m\u001b[34m(a, b, out)\u001b[39m\n\u001b[32m    700\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    701\u001b[39m \u001b[33;03m    result_type(*arrays_and_dtypes)\u001b[39;00m\n\u001b[32m    702\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    764\u001b[39m \n\u001b[32m    765\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arrays_and_dtypes\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath.dot)\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdot\u001b[39m(a, b, out=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    771\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    772\u001b[39m \u001b[33;03m    dot(a, b, out=None)\u001b[39;00m\n\u001b[32m    773\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    859\u001b[39m \n\u001b[32m    860\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    861\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, b, out)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from userreg import UserReg\n",
    "from userreg import WUserReg\n",
    "\n",
    "#Classic UserReg model evaluation\n",
    "# Load train/test splits\n",
    "R_train = np.load(\"data/ratings_train.npy\")\n",
    "R_test = np.load(\"data/ratings_test.npy\")\n",
    "\n",
    "print(f\"Train shape: {R_train.shape}, Test shape: {R_test.shape}\")\n",
    "\n",
    "for iter in range (1, 31, 2):\n",
    "    model = UserReg(k=8, lr=0.01, lambda_reg=0.02, beta_reg=8.0, bias_init=\"medium_adapted_mean\", num_iterations=iter)\n",
    "\n",
    "\n",
    "    # Fit on training data\n",
    "    model.fit(R_train)\n",
    "\n",
    "    # Predict full matrix\n",
    "    preds = model.predict()\n",
    "\n",
    "    # Evaluate only on test entries that are not NaN\n",
    "    mask_test = ~np.isnan(R_test)\n",
    "    true_values = R_test[mask_test]\n",
    "    pred_values = preds[mask_test]\n",
    "    pred_values = np.clip(pred_values, 1, 5)\n",
    "\n",
    "    # Compute RMSE\n",
    "    rmse = np.sqrt(np.mean((true_values - pred_values) ** 2))\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c7d3d",
   "metadata": {},
   "source": [
    "Simple UserReg with pre-ratings-normalization and post-denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "179f29d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (610, 4980), Test shape: (610, 4980)\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.9620\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.9202\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 5/5 [00:03<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.9053\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 7/7 [00:03<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.8972\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 9/9 [00:04<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.8921\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 11/11 [00:05<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.8887\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 13/13 [00:05<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.8863\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.8846\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.8834\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 19/19 [00:08<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.8825\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 21/21 [00:09<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.8819\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 23/23 [00:10<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.8814\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 25/25 [00:11<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.8811\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 27/27 [00:12<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.8810\n",
      "Starting global rating normalization on dense matrix...\n",
      "Global Mean: 3.52, Global Std Dev: 1.03\n",
      "Normalization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 29/29 [00:13<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting global denormalization...\n",
      "Denormalization complete.\n",
      "Test RMSE: 0.8809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from userreg import UserReg\n",
    "from userreg import WUserReg\n",
    "from functions.normalization import normalize_ratings, denormalize_predictions\n",
    "\n",
    "#Classic UserReg model evaluation\n",
    "# Load train/test splits\n",
    "R_train = np.load(\"data/ratings_train.npy\")\n",
    "R_test = np.load(\"data/ratings_test.npy\")\n",
    "\n",
    "print(f\"Train shape: {R_train.shape}, Test shape: {R_test.shape}\")\n",
    "\n",
    "for iter in range (1, 31, 2):\n",
    "    model = UserReg(k=8, lr=0.01, lambda_reg=0.02, beta_reg=8.0, bias_init=\"medium_adapted_mean\", num_iterations=iter)\n",
    "\n",
    "    R_train_normalized, stats = normalize_ratings(R_train)\n",
    "\n",
    "    model.fit(R_train_normalized)\n",
    "    preds = model.predict()\n",
    "\n",
    "    denormalized_preds = denormalize_predictions(preds, stats)\n",
    "\n",
    "    # Evaluate only on test entries that are not NaN\n",
    "    mask_test = ~np.isnan(R_test)\n",
    "    true_values = R_test[mask_test]\n",
    "    pred_values = denormalized_preds[mask_test]\n",
    "    pred_values = np.clip(pred_values, 0.5, 5)\n",
    "\n",
    "    \"\"\"print(R_train_normalized[:5, :5])\n",
    "    print(preds[:5, :5])\n",
    "    print(true_values[:10])\"\"\"\n",
    "\n",
    "    # Compute RMSE\n",
    "    rmse = np.sqrt(np.mean((true_values - pred_values) ** 2))\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c771f9fe",
   "metadata": {},
   "source": [
    "WUserReg Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (610, 4980), Test shape: (610, 4980)\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.4743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 12/12 [00:10<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from userreg import WUserReg\n",
    "\n",
    "# Load train/test splits\n",
    "R_train = np.load(\"data/ratings_train.npy\")\n",
    "R_test = np.load(\"data/ratings_test.npy\")\n",
    "\n",
    "print(f\"Train shape: {R_train.shape}, Test shape: {R_test.shape}\")\n",
    "\n",
    "model2 = WUserReg(k=8, lr=0.01, lambda_reg=0.02, beta_reg=8.0, bias_init=\"medium_adapted_mean\", num_iterations=12,\n",
    "                  alpha1=0, alpha2=0.2, m1=15, m2=25)\n",
    "\n",
    "\n",
    "# Fit on training data\n",
    "model2.fit(R_train)\n",
    "\n",
    "# Predict full matrix\n",
    "preds2 = model2.predict()\n",
    "\n",
    "\n",
    "# Evaluate only on test entries that are not NaN\n",
    "mask_test2 = ~np.isnan(R_test)\n",
    "true_values2 = R_test[mask_test2]\n",
    "pred_values2 = preds2[mask_test2]\n",
    "\n",
    "\n",
    "# Compute RMSE\n",
    "rmse2 = np.sqrt(np.mean((true_values2 - pred_values2) ** 2))\n",
    "print(f\"Test RMSE: {rmse2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f813d",
   "metadata": {},
   "source": [
    "Grid search for weights parameters for WUserReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5244a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0, alpha2=0, m1=10, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8902\n",
      "  *** NEW BEST MODEL ***\n",
      "(2/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0, alpha2=0, m1=10, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8902\n",
      "(3/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0, alpha2=0, m1=20, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8902\n",
      "(4/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0, alpha2=0, m1=20, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8902\n",
      "(5/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0, alpha2=0.15, m1=10, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.5948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9205\n",
      "(6/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0, alpha2=0.15, m1=10, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.5712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9098\n",
      "(7/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0, alpha2=0.15, m1=20, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.5948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9205\n",
      "(8/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0, alpha2=0.15, m1=20, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.5712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9098\n",
      "(9/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0, alpha2=0.25, m1=10, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.4218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9827\n",
      "(10/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0, alpha2=0.25, m1=10, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.3940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9504\n",
      "(11/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0, alpha2=0.25, m1=20, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.4218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9827\n",
      "(12/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0, alpha2=0.25, m1=20, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.3940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9504\n",
      "(13/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.15, alpha2=0, m1=10, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.4941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.0221\n",
      "(14/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.15, alpha2=0, m1=10, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.4941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:08<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.0221\n",
      "(15/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.15, alpha2=0, m1=20, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.4844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.0009\n",
      "(16/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.15, alpha2=0, m1=20, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.4844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.0009\n",
      "(17/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.15, alpha2=0.15, m1=10, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.2929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9909\n",
      "(18/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.15, alpha2=0.15, m1=10, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.2815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9937\n",
      "(19/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.15, alpha2=0.15, m1=20, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.2873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:08<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9752\n",
      "(20/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.15, alpha2=0.15, m1=20, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.2761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9768\n",
      "(21/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.15, alpha2=0.25, m1=10, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.2073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:08<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.0053\n",
      "(22/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.15, alpha2=0.25, m1=10, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.1939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:08<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9971\n",
      "(23/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.15, alpha2=0.25, m1=20, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.2034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9943\n",
      "(24/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.15, alpha2=0.25, m1=20, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.1901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9838\n",
      "(25/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.25, alpha2=0, m1=10, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.3124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.2359\n",
      "(26/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.25, alpha2=0, m1=10, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.3124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.2359\n",
      "(27/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.25, alpha2=0, m1=20, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1803\n",
      "(28/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.25, alpha2=0, m1=20, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1803\n",
      "(29/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.25, alpha2=0.15, m1=10, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1689\n",
      "(30/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.25, alpha2=0.15, m1=10, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.1777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1800\n",
      "(31/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.25, alpha2=0.15, m1=20, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.1785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1210\n",
      "(32/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.25, alpha2=0.15, m1=20, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.1716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1303\n",
      "(33/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.25, alpha2=0.25, m1=10, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.1307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1531\n",
      "(34/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.25, alpha2=0.25, m1=10, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1608\n",
      "(35/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.25, alpha2=0.25, m1=20, m2=16...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1118\n",
      "(36/36)\n",
      "Applying WANNLS matrix factorization with alpha1=0.25, alpha2=0.25, m1=20, m2=25...\n",
      "Found 31598 total ratings.\n",
      "Average un-normalized weight (w'_avg): 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UserReg: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1161\n",
      "\n",
      "Results saved to 'wannls_grid_search_results.csv'\n",
      "\n",
      "Top 10 models by RMSE:\n",
      "    alpha  alpha2  m1  m2      rmse\n",
      "0     0.0    0.00  10  16  0.890190\n",
      "1     0.0    0.00  10  25  0.890190\n",
      "2     0.0    0.00  20  16  0.890190\n",
      "3     0.0    0.00  20  25  0.890190\n",
      "5     0.0    0.15  10  25  0.909835\n",
      "7     0.0    0.15  20  25  0.909835\n",
      "4     0.0    0.15  10  16  0.920452\n",
      "6     0.0    0.15  20  16  0.920452\n",
      "9     0.0    0.25  10  25  0.950413\n",
      "11    0.0    0.25  20  25  0.950413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid search for weights parameters for WUserReg\n",
    "\n",
    "results = []\n",
    "best_rmse = float(\"inf\")\n",
    "best_params = None\n",
    "iter = 0 \n",
    "# Apply ALS matrix factorization\n",
    "for alpha1 in [0, 0.15, 0.25]:\n",
    "     for alpha2 in [0, 0.15, 0.25]:\n",
    "          for m1 in [10,20]:\n",
    "               for m2 in [16,25]:\n",
    "                iter += 1\n",
    "                print(f\"({iter}/36)\")\n",
    "                print(f\"Applying WANNLS matrix factorization with alpha1={alpha1}, alpha2={alpha2}, m1={m1}, m2={m2}...\")\n",
    "                model2 = WUserReg(k=8, lr=0.01, lambda_reg=0.02, beta_reg=8.0, bias_init=\"medium_adapted_mean\", num_iterations=10,\n",
    "                  alpha1=alpha1, alpha2=alpha2, m1=m1, m2=m2)\n",
    "\n",
    "\n",
    "                model2.fit(R_train)\n",
    "\n",
    "                preds2 = model2.predict()\n",
    "\n",
    "                mask_test2 = ~np.isnan(R_test)\n",
    "                true_values2 = R_test[mask_test2]\n",
    "                pred_values2 = preds2[mask_test2]\n",
    "\n",
    "                rmse_test2 = np.sqrt(np.mean((true_values2 - pred_values2) ** 2))\n",
    "                print(f\"Test RMSE: {rmse_test2:.4f}\")\n",
    "\n",
    "                results.append(\n",
    "                        {\n",
    "                            \"alpha\": alpha1,\n",
    "                            \"alpha2\": alpha2,\n",
    "                            \"m1\": m1,\n",
    "                            \"m2\": m2,\n",
    "                            \"rmse\": rmse_test2,\n",
    "                        }\n",
    "                    )\n",
    "                if rmse_test2 < best_rmse:\n",
    "                        best_rmse = rmse_test2\n",
    "                        best_params = {\n",
    "                            \"alpha\": alpha1,\n",
    "                            \"alpha2\": alpha2,\n",
    "                            \"m1\": m1,\n",
    "                            \"m2\": m2,\n",
    "                            \"rmse\": rmse_test2,\n",
    "                        }\n",
    "                        print(f\"  *** NEW BEST MODEL ***\")\n",
    "                \n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"WUserReg_grid_search_results.csv\", index=False)\n",
    "print(f\"\\nResults saved to 'wannls_grid_search_results.csv'\")\n",
    "\n",
    "\n",
    "print(\"\\nTop 10 models by RMSE:\")\n",
    "print(results_df.nsmallest(10, \"rmse\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96325bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (610, 4980) (users × items)\n",
      "Running 3-fold cross-validation...\n",
      "\n",
      "Fold 1/3\n",
      "  RMSE = 0.9109 | MAE = 0.7082\n",
      "\n",
      "Fold 2/3\n",
      "  RMSE = 0.9075 | MAE = 0.7064\n",
      "\n",
      "Fold 3/3\n",
      "  RMSE = 0.9084 | MAE = 0.7075\n",
      "\n",
      "Average RMSE: 0.9089 ± 0.0014\n",
      "Average MAE : 0.7074 ± 0.0007\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------- Combine Train/Test ----------\n",
    "R_train = np.load(\"data/ratings_train.npy\")\n",
    "R_test = np.load(\"data/ratings_test.npy\")\n",
    "\n",
    "\n",
    "R_combined = np.where(~np.isnan(R_train), R_train, R_test)\n",
    "print(f\"Combined dataset shape: {R_combined.shape} (users × items)\")\n",
    "\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def train_test_split_per_user(R, test_ratio=0.2, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    n_users, _ = R.shape\n",
    "    R_train = np.full_like(R, np.nan)\n",
    "    R_test = np.full_like(R, np.nan)\n",
    "\n",
    "    for u in range(n_users):\n",
    "        items = np.where(~np.isnan(R[u]))[0]\n",
    "        if len(items) == 0:\n",
    "            continue\n",
    "        np.random.shuffle(items)\n",
    "        split = int(len(items) * (1 - test_ratio))\n",
    "        R_train[u, items[:split]] = R[u, items[:split]]\n",
    "        R_test[u, items[split:]] = R[u, items[split:]]\n",
    "    return R_train, R_test\n",
    "\n",
    "\n",
    "def generate_kfold_splits(R, k=5, test_ratio=0.5):\n",
    "    return [train_test_split_random(R, test_ratio=test_ratio, seed=i) for i in range(k)]\n",
    "\n",
    "\n",
    "# ---------- K-fold evaluation ----------\n",
    "def evaluate_kfold(R, k=5, test_ratio=0.2,\n",
    "                   latent_dim=10, lr=0.005, lambda_reg=0.1, beta_reg=8.0, epochs=60):\n",
    "                   \n",
    "    rmses, maes = [], []\n",
    "    splits = generate_kfold_splits(R, k=k, test_ratio=test_ratio)\n",
    "    print(f\"Running {k}-fold cross-validation...\")\n",
    "\n",
    "    for fold, (R_tr, R_te) in enumerate(splits, 1):\n",
    "        print(f\"\\nFold {fold}/{k}\")\n",
    "        model = UserReg(k=latent_dim, lr=lr, lambda_reg=lambda_reg,\n",
    "                        beta_reg=beta_reg, num_iterations=epochs, verbose=False)\n",
    "        model.fit(R_tr)\n",
    "        preds = model.predict()\n",
    "\n",
    "        mask = ~np.isnan(R_te)\n",
    "        true, pred = R_te[mask], preds[mask]\n",
    "        rmse = np.sqrt(np.mean((true - pred) ** 2))\n",
    "        mae = np.mean(np.abs(true - pred))\n",
    "        rmses.append(rmse)\n",
    "        maes.append(mae)\n",
    "        print(f\"  RMSE = {rmse:.4f} | MAE = {mae:.4f}\")\n",
    "\n",
    "    print(f\"\\nAverage RMSE: {np.mean(rmses):.4f} ± {np.std(rmses):.4f}\")\n",
    "    print(f\"Average MAE : {np.mean(maes):.4f} ± {np.std(maes):.4f}\")\n",
    "    return rmses, maes\n",
    "\n",
    "\n",
    "# ---------- Run evaluation ----------\n",
    "rmses, maes = evaluate_kfold(\n",
    "    R_combined,\n",
    "    k=3,\n",
    "    test_ratio=0.5,\n",
    "    latent_dim=5,\n",
    "    lr=0.01,\n",
    "    lambda_reg=0.05,\n",
    "    beta_reg=8.0,\n",
    "    epochs=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18bf5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9e5477f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (610, 4980) (users × items)\n",
      "Total combinations: 162\n",
      "Testing k=5, λ=0.05, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0761 ± 0.0022\n",
      "Testing k=5, λ=0.05, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0761 ± 0.0022\n",
      "Testing k=5, λ=0.05, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0059 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0059 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9457 ± 0.0018\n",
      "Testing k=5, λ=0.05, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9457 ± 0.0018\n",
      "Testing k=5, λ=0.05, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9178 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9178 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9073 ± 0.0018\n",
      "Testing k=5, λ=0.05, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9073 ± 0.0018\n",
      "Testing k=5, λ=0.05, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.8992 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 0.8992 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0761 ± 0.0022\n",
      "Testing k=5, λ=0.05, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0761 ± 0.0022\n",
      "Testing k=5, λ=0.05, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0059 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0059 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9457 ± 0.0018\n",
      "Testing k=5, λ=0.05, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9457 ± 0.0018\n",
      "Testing k=5, λ=0.05, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9178 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9178 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9073 ± 0.0018\n",
      "Testing k=5, λ=0.05, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9073 ± 0.0018\n",
      "Testing k=5, λ=0.05, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.8992 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 0.8992 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0761 ± 0.0022\n",
      "Testing k=5, λ=0.05, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0761 ± 0.0022\n",
      "Testing k=5, λ=0.05, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0059 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0059 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9457 ± 0.0018\n",
      "Testing k=5, λ=0.05, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9457 ± 0.0018\n",
      "Testing k=5, λ=0.05, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9178 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9178 ± 0.0017\n",
      "Testing k=5, λ=0.05, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9073 ± 0.0018\n",
      "Testing k=5, λ=0.05, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9073 ± 0.0018\n",
      "Testing k=5, λ=0.05, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.8992 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 0.8992 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0938 ± 0.0021\n",
      "Testing k=5, λ=0.1, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0938 ± 0.0021\n",
      "Testing k=5, λ=0.1, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0253 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0253 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9650 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9650 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9396 ± 0.0016\n",
      "Testing k=5, λ=0.1, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9396 ± 0.0016\n",
      "Testing k=5, λ=0.1, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9266 ± 0.0018\n",
      "Testing k=5, λ=0.1, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9266 ± 0.0018\n",
      "Testing k=5, λ=0.1, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9196 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9196 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0938 ± 0.0021\n",
      "Testing k=5, λ=0.1, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0938 ± 0.0021\n",
      "Testing k=5, λ=0.1, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0253 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0253 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9650 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9650 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9396 ± 0.0016\n",
      "Testing k=5, λ=0.1, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9396 ± 0.0016\n",
      "Testing k=5, λ=0.1, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9266 ± 0.0018\n",
      "Testing k=5, λ=0.1, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9266 ± 0.0018\n",
      "Testing k=5, λ=0.1, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9196 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9196 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0938 ± 0.0021\n",
      "Testing k=5, λ=0.1, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0938 ± 0.0021\n",
      "Testing k=5, λ=0.1, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0253 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0253 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9650 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9650 ± 0.0017\n",
      "Testing k=5, λ=0.1, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9396 ± 0.0016\n",
      "Testing k=5, λ=0.1, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9396 ± 0.0016\n",
      "Testing k=5, λ=0.1, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9266 ± 0.0018\n",
      "Testing k=5, λ=0.1, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9266 ± 0.0018\n",
      "Testing k=5, λ=0.1, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9196 ± 0.0017\n",
      "Testing k=5, λ=0.2, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9196 ± 0.0017\n",
      "Testing k=5, λ=0.2, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 1.1479 ± 0.0018\n",
      "Testing k=5, λ=0.2, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.1479 ± 0.0018\n",
      "Testing k=5, λ=0.2, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0835 ± 0.0015\n",
      "Testing k=5, λ=0.2, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0835 ± 0.0015\n",
      "Testing k=5, λ=0.2, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0225 ± 0.0016\n",
      "Testing k=5, λ=0.2, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 1.0225 ± 0.0016\n",
      "Testing k=5, λ=0.2, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9990 ± 0.0016\n",
      "Testing k=5, λ=0.2, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9990 ± 0.0016\n",
      "Testing k=5, λ=0.2, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9803 ± 0.0017\n",
      "Testing k=5, λ=0.2, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9803 ± 0.0017\n",
      "Testing k=5, λ=0.2, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9718 ± 0.0017\n",
      "Testing k=5, λ=0.2, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9718 ± 0.0017\n",
      "Testing k=5, λ=0.2, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 1.1479 ± 0.0018\n",
      "Testing k=5, λ=0.2, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.1479 ± 0.0018\n",
      "Testing k=5, λ=0.2, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0835 ± 0.0015\n",
      "Testing k=5, λ=0.2, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0835 ± 0.0015\n",
      "Testing k=5, λ=0.2, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0225 ± 0.0016\n",
      "Testing k=5, λ=0.2, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 1.0225 ± 0.0016\n",
      "Testing k=5, λ=0.2, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9990 ± 0.0016\n",
      "Testing k=5, λ=0.2, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9990 ± 0.0016\n",
      "Testing k=5, λ=0.2, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9803 ± 0.0017\n",
      "Testing k=5, λ=0.2, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9803 ± 0.0017\n",
      "Testing k=5, λ=0.2, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9718 ± 0.0017\n",
      "Testing k=5, λ=0.2, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9718 ± 0.0017\n",
      "Testing k=5, λ=0.2, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 1.1479 ± 0.0018\n",
      "Testing k=5, λ=0.2, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.1479 ± 0.0018\n",
      "Testing k=5, λ=0.2, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0835 ± 0.0015\n",
      "Testing k=5, λ=0.2, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0835 ± 0.0015\n",
      "Testing k=5, λ=0.2, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0225 ± 0.0016\n",
      "Testing k=5, λ=0.2, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 1.0225 ± 0.0016\n",
      "Testing k=5, λ=0.2, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9990 ± 0.0016\n",
      "Testing k=5, λ=0.2, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9990 ± 0.0016\n",
      "Testing k=5, λ=0.2, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9803 ± 0.0017\n",
      "Testing k=5, λ=0.2, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9803 ± 0.0017\n",
      "Testing k=5, λ=0.2, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9718 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9718 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0765 ± 0.0022\n",
      "Testing k=10, λ=0.05, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0765 ± 0.0022\n",
      "Testing k=10, λ=0.05, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0062 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0062 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9461 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9461 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9181 ± 0.0016\n",
      "Testing k=10, λ=0.05, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9181 ± 0.0016\n",
      "Testing k=10, λ=0.05, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9075 ± 0.0018\n",
      "Testing k=10, λ=0.05, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9075 ± 0.0018\n",
      "Testing k=10, λ=0.05, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.8994 ± 0.0016\n",
      "Testing k=10, λ=0.05, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 0.8994 ± 0.0016\n",
      "Testing k=10, λ=0.05, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0764 ± 0.0022\n",
      "Testing k=10, λ=0.05, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0764 ± 0.0022\n",
      "Testing k=10, λ=0.05, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0062 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0062 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9460 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9460 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9181 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9181 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9075 ± 0.0018\n",
      "Testing k=10, λ=0.05, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9075 ± 0.0018\n",
      "Testing k=10, λ=0.05, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.8994 ± 0.0016\n",
      "Testing k=10, λ=0.05, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 0.8994 ± 0.0016\n",
      "Testing k=10, λ=0.05, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0764 ± 0.0022\n",
      "Testing k=10, λ=0.05, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0764 ± 0.0022\n",
      "Testing k=10, λ=0.05, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0062 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0062 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9460 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9460 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9181 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9181 ± 0.0017\n",
      "Testing k=10, λ=0.05, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9075 ± 0.0018\n",
      "Testing k=10, λ=0.05, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9075 ± 0.0018\n",
      "Testing k=10, λ=0.05, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.8994 ± 0.0016\n",
      "Testing k=10, λ=0.1, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 0.8994 ± 0.0016\n",
      "Testing k=10, λ=0.1, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0941 ± 0.0021\n",
      "Testing k=10, λ=0.1, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0941 ± 0.0021\n",
      "Testing k=10, λ=0.1, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0256 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0256 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9653 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9653 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9399 ± 0.0016\n",
      "Testing k=10, λ=0.1, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9399 ± 0.0016\n",
      "Testing k=10, λ=0.1, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9267 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9267 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9197 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9197 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0941 ± 0.0021\n",
      "Testing k=10, λ=0.1, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0941 ± 0.0021\n",
      "Testing k=10, λ=0.1, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0256 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0256 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9652 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9652 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9399 ± 0.0016\n",
      "Testing k=10, λ=0.1, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9399 ± 0.0016\n",
      "Testing k=10, λ=0.1, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9267 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9267 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9197 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9197 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0941 ± 0.0021\n",
      "Testing k=10, λ=0.1, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0941 ± 0.0021\n",
      "Testing k=10, λ=0.1, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0256 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0256 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9652 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9652 ± 0.0017\n",
      "Testing k=10, λ=0.1, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9399 ± 0.0016\n",
      "Testing k=10, λ=0.1, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9399 ± 0.0016\n",
      "Testing k=10, λ=0.1, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9267 ± 0.0018\n",
      "Testing k=10, λ=0.1, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9267 ± 0.0018\n",
      "Testing k=10, λ=0.1, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9197 ± 0.0017\n",
      "Testing k=10, λ=0.2, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9197 ± 0.0017\n",
      "Testing k=10, λ=0.2, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 1.1482 ± 0.0018\n",
      "Testing k=10, λ=0.2, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.1482 ± 0.0018\n",
      "Testing k=10, λ=0.2, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0838 ± 0.0015\n",
      "Testing k=10, λ=0.2, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0838 ± 0.0015\n",
      "Testing k=10, λ=0.2, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0227 ± 0.0016\n",
      "Testing k=10, λ=0.2, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 1.0227 ± 0.0016\n",
      "Testing k=10, λ=0.2, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9992 ± 0.0016\n",
      "Testing k=10, λ=0.2, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9992 ± 0.0016\n",
      "Testing k=10, λ=0.2, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9804 ± 0.0017\n",
      "Testing k=10, λ=0.2, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9804 ± 0.0017\n",
      "Testing k=10, λ=0.2, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9718 ± 0.0017\n",
      "Testing k=10, λ=0.2, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9718 ± 0.0017\n",
      "Testing k=10, λ=0.2, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 1.1482 ± 0.0018\n",
      "Testing k=10, λ=0.2, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.1482 ± 0.0018\n",
      "Testing k=10, λ=0.2, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0837 ± 0.0015\n",
      "Testing k=10, λ=0.2, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0837 ± 0.0015\n",
      "Testing k=10, λ=0.2, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0227 ± 0.0016\n",
      "Testing k=10, λ=0.2, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 1.0227 ± 0.0016\n",
      "Testing k=10, λ=0.2, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9992 ± 0.0016\n",
      "Testing k=10, λ=0.2, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9992 ± 0.0016\n",
      "Testing k=10, λ=0.2, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9804 ± 0.0017\n",
      "Testing k=10, λ=0.2, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9804 ± 0.0017\n",
      "Testing k=10, λ=0.2, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9718 ± 0.0017\n",
      "Testing k=10, λ=0.2, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9718 ± 0.0017\n",
      "Testing k=10, λ=0.2, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 1.1482 ± 0.0018\n",
      "Testing k=10, λ=0.2, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.1482 ± 0.0018\n",
      "Testing k=10, λ=0.2, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0837 ± 0.0015\n",
      "Testing k=10, λ=0.2, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0837 ± 0.0015\n",
      "Testing k=10, λ=0.2, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0227 ± 0.0016\n",
      "Testing k=10, λ=0.2, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 1.0227 ± 0.0016\n",
      "Testing k=10, λ=0.2, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9992 ± 0.0016\n",
      "Testing k=10, λ=0.2, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9992 ± 0.0016\n",
      "Testing k=10, λ=0.2, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9804 ± 0.0017\n",
      "Testing k=10, λ=0.2, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9804 ± 0.0017\n",
      "Testing k=10, λ=0.2, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9718 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9718 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0770 ± 0.0021\n",
      "Testing k=20, λ=0.05, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0770 ± 0.0021\n",
      "Testing k=20, λ=0.05, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0067 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0067 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9464 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9464 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9184 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9184 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9078 ± 0.0018\n",
      "Testing k=20, λ=0.05, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9078 ± 0.0018\n",
      "Testing k=20, λ=0.05, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.8996 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 0.8996 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0770 ± 0.0021\n",
      "Testing k=20, λ=0.05, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0770 ± 0.0021\n",
      "Testing k=20, λ=0.05, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0067 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0067 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9464 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9464 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9184 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9184 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9078 ± 0.0018\n",
      "Testing k=20, λ=0.05, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9078 ± 0.0018\n",
      "Testing k=20, λ=0.05, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.8996 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 0.8996 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0769 ± 0.0022\n",
      "Testing k=20, λ=0.05, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0769 ± 0.0022\n",
      "Testing k=20, λ=0.05, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0067 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0067 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9464 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9464 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9184 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9184 ± 0.0017\n",
      "Testing k=20, λ=0.05, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9078 ± 0.0018\n",
      "Testing k=20, λ=0.05, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9078 ± 0.0018\n",
      "Testing k=20, λ=0.05, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.8996 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 0.8996 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0946 ± 0.0020\n",
      "Testing k=20, λ=0.1, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0946 ± 0.0020\n",
      "Testing k=20, λ=0.1, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0261 ± 0.0016\n",
      "Testing k=20, λ=0.1, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0261 ± 0.0016\n",
      "Testing k=20, λ=0.1, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9657 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9657 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9402 ± 0.0016\n",
      "Testing k=20, λ=0.1, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9402 ± 0.0016\n",
      "Testing k=20, λ=0.1, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9270 ± 0.0018\n",
      "Testing k=20, λ=0.1, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9270 ± 0.0018\n",
      "Testing k=20, λ=0.1, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9199 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9199 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0946 ± 0.0020\n",
      "Testing k=20, λ=0.1, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0946 ± 0.0020\n",
      "Testing k=20, λ=0.1, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0261 ± 0.0016\n",
      "Testing k=20, λ=0.1, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0261 ± 0.0016\n",
      "Testing k=20, λ=0.1, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9656 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9656 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9402 ± 0.0016\n",
      "Testing k=20, λ=0.1, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9402 ± 0.0016\n",
      "Testing k=20, λ=0.1, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9270 ± 0.0018\n",
      "Testing k=20, λ=0.1, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9270 ± 0.0018\n",
      "Testing k=20, λ=0.1, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9199 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9199 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 1.0946 ± 0.0020\n",
      "Testing k=20, λ=0.1, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0946 ± 0.0020\n",
      "Testing k=20, λ=0.1, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0261 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0261 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 0.9656 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9656 ± 0.0017\n",
      "Testing k=20, λ=0.1, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9402 ± 0.0016\n",
      "Testing k=20, λ=0.1, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9402 ± 0.0016\n",
      "Testing k=20, λ=0.1, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9270 ± 0.0018\n",
      "Testing k=20, λ=0.1, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9270 ± 0.0018\n",
      "Testing k=20, λ=0.1, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9199 ± 0.0017\n",
      "Testing k=20, λ=0.2, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9199 ± 0.0017\n",
      "Testing k=20, λ=0.2, β=8, lr=0.002, epochs=20\n",
      "  → RMSE: 1.1488 ± 0.0018\n",
      "Testing k=20, λ=0.2, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.1488 ± 0.0018\n",
      "Testing k=20, λ=0.2, β=8, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0842 ± 0.0015\n",
      "Testing k=20, λ=0.2, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0842 ± 0.0015\n",
      "Testing k=20, λ=0.2, β=8, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0231 ± 0.0016\n",
      "Testing k=20, λ=0.2, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 1.0231 ± 0.0016\n",
      "Testing k=20, λ=0.2, β=8, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9995 ± 0.0016\n",
      "Testing k=20, λ=0.2, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9995 ± 0.0016\n",
      "Testing k=20, λ=0.2, β=8, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9806 ± 0.0017\n",
      "Testing k=20, λ=0.2, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9806 ± 0.0017\n",
      "Testing k=20, λ=0.2, β=8, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9720 ± 0.0017\n",
      "Testing k=20, λ=0.2, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9720 ± 0.0017\n",
      "Testing k=20, λ=0.2, β=12, lr=0.002, epochs=20\n",
      "  → RMSE: 1.1487 ± 0.0018\n",
      "Testing k=20, λ=0.2, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.1487 ± 0.0018\n",
      "Testing k=20, λ=0.2, β=12, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0842 ± 0.0015\n",
      "Testing k=20, λ=0.2, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0842 ± 0.0015\n",
      "Testing k=20, λ=0.2, β=12, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0230 ± 0.0016\n",
      "Testing k=20, λ=0.2, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 1.0230 ± 0.0016\n",
      "Testing k=20, λ=0.2, β=12, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9995 ± 0.0016\n",
      "Testing k=20, λ=0.2, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9995 ± 0.0016\n",
      "Testing k=20, λ=0.2, β=12, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9806 ± 0.0017\n",
      "Testing k=20, λ=0.2, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9806 ± 0.0017\n",
      "Testing k=20, λ=0.2, β=12, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9720 ± 0.0017\n",
      "Testing k=20, λ=0.2, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 0.9720 ± 0.0017\n",
      "Testing k=20, λ=0.2, β=16, lr=0.002, epochs=20\n",
      "  → RMSE: 1.1487 ± 0.0018\n",
      "Testing k=20, λ=0.2, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.1487 ± 0.0018\n",
      "Testing k=20, λ=0.2, β=16, lr=0.002, epochs=30\n",
      "  → RMSE: 1.0842 ± 0.0015\n",
      "Testing k=20, λ=0.2, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0842 ± 0.0015\n",
      "Testing k=20, λ=0.2, β=16, lr=0.005, epochs=20\n",
      "  → RMSE: 1.0230 ± 0.0016\n",
      "Testing k=20, λ=0.2, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 1.0230 ± 0.0016\n",
      "Testing k=20, λ=0.2, β=16, lr=0.005, epochs=30\n",
      "  → RMSE: 0.9994 ± 0.0016\n",
      "Testing k=20, λ=0.2, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9994 ± 0.0016\n",
      "Testing k=20, λ=0.2, β=16, lr=0.01, epochs=20\n",
      "  → RMSE: 0.9806 ± 0.0017\n",
      "Testing k=20, λ=0.2, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9806 ± 0.0017\n",
      "Testing k=20, λ=0.2, β=16, lr=0.01, epochs=30\n",
      "  → RMSE: 0.9720 ± 0.0017\n",
      "\n",
      "===== Hyperparameter Tuning Results =====\n",
      "    k  lambda_reg  beta_reg    lr  epochs  mean_rmse  std_rmse\n",
      "0   5        0.05         8  0.01      30   0.899186  0.001673\n",
      "1   5        0.05        12  0.01      30   0.899189  0.001672\n",
      "2   5        0.05        16  0.01      30   0.899191  0.001671\n",
      "3  10        0.05        12  0.01      30   0.899357  0.001632\n",
      "4  10        0.05        16  0.01      30   0.899357  0.001633\n",
      "5  10        0.05         8  0.01      30   0.899358  0.001630\n",
      "6  20        0.05        16  0.01      30   0.899564  0.001663\n",
      "7  20        0.05        12  0.01      30   0.899567  0.001662\n",
      "8  20        0.05         8  0.01      30   0.899575  0.001661\n",
      "9   5        0.05         8  0.01      20   0.907298  0.001822\n",
      "\n",
      "✅ Best configuration:\n",
      "k              5.000000\n",
      "lambda_reg     0.050000\n",
      "beta_reg       8.000000\n",
      "lr             0.010000\n",
      "epochs        30.000000\n",
      "mean_rmse      0.899186\n",
      "std_rmse       0.001673\n",
      "Name: 0, dtype: float64\n",
      "  → RMSE: 0.9720 ± 0.0017\n",
      "\n",
      "===== Hyperparameter Tuning Results =====\n",
      "    k  lambda_reg  beta_reg    lr  epochs  mean_rmse  std_rmse\n",
      "0   5        0.05         8  0.01      30   0.899186  0.001673\n",
      "1   5        0.05        12  0.01      30   0.899189  0.001672\n",
      "2   5        0.05        16  0.01      30   0.899191  0.001671\n",
      "3  10        0.05        12  0.01      30   0.899357  0.001632\n",
      "4  10        0.05        16  0.01      30   0.899357  0.001633\n",
      "5  10        0.05         8  0.01      30   0.899358  0.001630\n",
      "6  20        0.05        16  0.01      30   0.899564  0.001663\n",
      "7  20        0.05        12  0.01      30   0.899567  0.001662\n",
      "8  20        0.05         8  0.01      30   0.899575  0.001661\n",
      "9   5        0.05         8  0.01      20   0.907298  0.001822\n",
      "\n",
      "✅ Best configuration:\n",
      "k              5.000000\n",
      "lambda_reg     0.050000\n",
      "beta_reg       8.000000\n",
      "lr             0.010000\n",
      "epochs        30.000000\n",
      "mean_rmse      0.899186\n",
      "std_rmse       0.001673\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from userreg import UserReg\n",
    "\n",
    "\n",
    "# ---------- Load & Combine ----------\n",
    "R_train = np.load(\"data/ratings_train.npy\")\n",
    "R_test = np.load(\"data/ratings_test.npy\")\n",
    "R = np.where(~np.isnan(R_train), R_train, R_test)\n",
    "print(f\"Combined dataset shape: {R.shape} (users × items)\")\n",
    "\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def train_test_split_random(R, test_ratio=0.2, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    idx = np.argwhere(~np.isnan(R))\n",
    "    n_total = len(idx)\n",
    "    n_test = int(n_total * test_ratio)\n",
    "    perm = np.random.permutation(n_total)\n",
    "    test_idx = idx[perm[:n_test]]\n",
    "    train_idx = idx[perm[n_test:]]\n",
    "    R_train = np.full_like(R, np.nan)\n",
    "    R_test = np.full_like(R, np.nan)\n",
    "    R_train[tuple(train_idx.T)] = R[tuple(train_idx.T)]\n",
    "    R_test[tuple(test_idx.T)] = R[tuple(test_idx.T)]\n",
    "    return R_train, R_test\n",
    "\n",
    "\n",
    "def generate_kfold_splits(R, k=3, test_ratio=0.3):\n",
    "    return [train_test_split_random(R, test_ratio=test_ratio, seed=i) for i in range(k)]\n",
    "\n",
    "\n",
    "def evaluate_model(R, k_folds=3, **params):\n",
    "    splits = generate_kfold_splits(R, k=k_folds, test_ratio=0.3)\n",
    "    rmses = []\n",
    "    for (R_tr, R_te) in splits:\n",
    "        model = UserReg(verbose=False, **params)\n",
    "        model.fit(R_tr)\n",
    "        preds = model.predict()\n",
    "        mask = ~np.isnan(R_te)\n",
    "        true, pred = R_te[mask], preds[mask]\n",
    "        rmse = np.sqrt(np.mean((true - pred) ** 2))\n",
    "        rmses.append(rmse)\n",
    "    return np.mean(rmses), np.std(rmses)\n",
    "\n",
    "\n",
    "# ---------- Define hyperparameter grid ----------\n",
    "param_grid = {\n",
    "    \"k\": [5, 10, 20],\n",
    "    \"lambda_reg\": [0.05, 0.1, 0.2],\n",
    "    \"beta_reg\": [ 8, 12, 16],\n",
    "    \"lr\": [0.002, 0.005, 0.01],\n",
    "    \"num_iterations\": [20, 30]\n",
    "}\n",
    "k_folds = 3  # 3-fold for speed\n",
    "\n",
    "# Generate all combinations\n",
    "grid_combos = list(itertools.product(\n",
    "    param_grid[\"k\"],\n",
    "    param_grid[\"lambda_reg\"],\n",
    "    param_grid[\"beta_reg\"],\n",
    "    param_grid[\"lr\"],\n",
    "    param_grid[\"num_iterations\"]\n",
    "))\n",
    "\n",
    "print(f\"Total combinations: {len(grid_combos)}\")\n",
    "\n",
    "\n",
    "# ---------- Run grid search ----------\n",
    "results = []\n",
    "for (k_lat, lam, beta, lr, epochs) in grid_combos:\n",
    "    print(f\"Testing k={k_lat}, λ={lam}, β={beta}, lr={lr}, epochs={epochs}\")\n",
    "    mean_rmse, std_rmse = evaluate_model(\n",
    "        R,\n",
    "        k_folds=k_folds,\n",
    "        k=k_lat,\n",
    "        lr=lr,\n",
    "        lambda_reg=lam,\n",
    "        beta_reg=beta,\n",
    "        num_iterations=epochs\n",
    "    )\n",
    "    results.append({\n",
    "        \"k\": k_lat,\n",
    "        \"lambda_reg\": lam,\n",
    "        \"beta_reg\": beta,\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": epochs,\n",
    "        \"mean_rmse\": mean_rmse,\n",
    "        \"std_rmse\": std_rmse\n",
    "    })\n",
    "    print(f\"  → RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "\n",
    "\n",
    "# ---------- Display and visualize ----------\n",
    "df = pd.DataFrame(results).sort_values(by=\"mean_rmse\").reset_index(drop=True)\n",
    "print(\"\\n===== Hyperparameter Tuning Results =====\")\n",
    "print(df.head(10))\n",
    "\n",
    "best = df.iloc[0]\n",
    "print(\"\\n✅ Best configuration:\")\n",
    "print(best)\n",
    "\n",
    "# --- Visualization (RMSE vs single hyperparameter trends) ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "for param in [\"k\", \"lambda_reg\", \"beta_reg\", \"lr\", \"epochs\"]:\n",
    "    plt.subplot(1, 5, [\"k\", \"lambda_reg\", \"beta_reg\", \"lr\", \"epochs\"].index(param) + 1)\n",
    "    plt.scatter(df[param], df[\"mean_rmse\"], alpha=0.7)\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"RMSE\" if param == \"k\" else \"\")\n",
    "    plt.title(param)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0125f",
   "metadata": {},
   "source": [
    "## Grid search with global random split (not per-user)\n",
    "This section re-runs hyperparameter search using a global, entry-wise random split of observed ratings into train/test, repeated across k folds for robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0afed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from userreg import UserReg\n",
    "\n",
    "# --- Load combined observed ratings ---\n",
    "R_train = np.load(\"data/ratings_train.npy\")\n",
    "R_test = np.load(\"data/ratings_test.npy\")\n",
    "R = np.where(~np.isnan(R_train), R_train, R_test)\n",
    "print(f\"Combined dataset shape: {R.shape} (users × items)\")\n",
    "\n",
    "# --- Global random entry-wise split ---\n",
    "def train_test_split_random(R, test_ratio=0.2, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    obs = np.argwhere(~np.isnan(R))\n",
    "    n_total = len(obs)\n",
    "    n_test = int(n_total * test_ratio)\n",
    "    perm = rng.permutation(n_total)\n",
    "    test_idx = obs[perm[:n_test]]\n",
    "    train_idx = obs[perm[n_test:]]\n",
    "    R_train = np.full_like(R, np.nan)\n",
    "    R_test = np.full_like(R, np.nan)\n",
    "    R_train[tuple(train_idx.T)] = R[tuple(train_idx.T)]\n",
    "    R_test[tuple(test_idx.T)] = R[tuple(test_idx.T)]\n",
    "    return R_train, R_test\n",
    "\n",
    "# --- K folds built from independent random splits ---\n",
    "def generate_kfold_splits(R, k=3, test_ratio=0.2):\n",
    "    return [train_test_split_random(R, test_ratio=test_ratio, seed=i) for i in range(k)]\n",
    "\n",
    "# --- Evaluation for a single config ---\n",
    "def evaluate_model(R, k_folds=3, **params):\n",
    "    splits = generate_kfold_splits(R, k=k_folds, test_ratio=0.2)\n",
    "    rmses = []\n",
    "    for (R_tr, R_te) in splits:\n",
    "        model = UserReg(verbose=False, **params)\n",
    "        model.fit(R_tr)\n",
    "        preds = model.predict()\n",
    "        mask = ~np.isnan(R_te)\n",
    "        true, pred = R_te[mask], preds[mask]\n",
    "        rmse = np.sqrt(np.mean((true - pred) ** 2))\n",
    "        rmses.append(rmse)\n",
    "    return float(np.mean(rmses)), float(np.std(rmses))\n",
    "\n",
    "# --- Hyperparameter grid ---\n",
    "param_grid = {\n",
    "    \"k\": [5, 10, 20],\n",
    "    \"lambda_reg\": [0.05, 0.1, 0.2],\n",
    "    \"beta_reg\": [8, 12, 16],\n",
    "    \"lr\": [0.002, 0.005, 0.01],\n",
    "    \"num_iterations\": [20, 30],\n",
    "}\n",
    "\n",
    "# Cartesian product of grid\n",
    "grid_combos = list(itertools.product(\n",
    "    param_grid[\"k\"],\n",
    "    param_grid[\"lambda_reg\"],\n",
    "    param_grid[\"beta_reg\"],\n",
    "    param_grid[\"lr\"],\n",
    "    param_grid[\"num_iterations\"],\n",
    "))\n",
    "print(f\"Total combinations: {len(grid_combos)}\")\n",
    "\n",
    "# --- Grid search ---\n",
    "results = []\n",
    "for (k_lat, lam, beta, lr, epochs) in grid_combos:\n",
    "    print(f\"Testing k={k_lat}, λ={lam}, β={beta}, lr={lr}, epochs={epochs}\")\n",
    "    mean_rmse, std_rmse = evaluate_model(\n",
    "        R,\n",
    "        k_folds=3,\n",
    "        k=k_lat,\n",
    "        lr=lr,\n",
    "        lambda_reg=lam,\n",
    "        beta_reg=beta,\n",
    "        num_iterations=epochs,\n",
    "    )\n",
    "    results.append({\n",
    "        \"k\": k_lat,\n",
    "        \"lambda_reg\": lam,\n",
    "        \"beta_reg\": beta,\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": epochs,\n",
    "        \"mean_rmse\": mean_rmse,\n",
    "        \"std_rmse\": std_rmse,\n",
    "    })\n",
    "    print(f\"  → RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "\n",
    "# --- Display results ---\n",
    "df = pd.DataFrame(results).sort_values(by=\"mean_rmse\").reset_index(drop=True)\n",
    "print(\"\\n===== Global random-split Grid Search Results =====\")\n",
    "print(df.head(10))\n",
    "print(\"\\nBest:\")\n",
    "print(df.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_lab_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
